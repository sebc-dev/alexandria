---
phase: 04-ingestion-pipeline
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - gradle/libs.versions.toml
  - build.gradle.kts
  - src/main/java/dev/alexandria/ingestion/chunking/MarkdownChunker.java
  - src/main/java/dev/alexandria/ingestion/chunking/DocumentChunkData.java
  - src/main/java/dev/alexandria/ingestion/chunking/LanguageDetector.java
  - src/test/java/dev/alexandria/ingestion/chunking/MarkdownChunkerTest.java
  - src/test/java/dev/alexandria/ingestion/chunking/LanguageDetectorTest.java
autonomous: true
must_haves:
  truths:
    - "Markdown is split into chunks at H1/H2/H3 boundaries only"
    - "H4+ headings remain inside parent H3 chunk"
    - "Fenced code blocks are extracted as separate chunks with content_type=code"
    - "Prose chunks retain text minus extracted code blocks with content_type=prose"
    - "Every chunk carries all 5 metadata fields: source_url, section_path, content_type, last_updated, language"
    - "section_path uses slash separator built from heading hierarchy"
    - "Code language is detected from fence info string or by keyword heuristic"
    - "Headings inside fenced code blocks do NOT trigger chunk splits"
  artifacts:
    - path: "src/main/java/dev/alexandria/ingestion/chunking/MarkdownChunker.java"
      provides: "AST-based Markdown heading splitter and code extractor"
      min_lines: 80
    - path: "src/main/java/dev/alexandria/ingestion/chunking/DocumentChunkData.java"
      provides: "Record holding chunk text + 5 metadata fields"
      contains: "record DocumentChunkData"
    - path: "src/main/java/dev/alexandria/ingestion/chunking/LanguageDetector.java"
      provides: "Keyword-based code language detection heuristic"
      contains: "detect"
    - path: "src/test/java/dev/alexandria/ingestion/chunking/MarkdownChunkerTest.java"
      provides: "Unit tests for chunking logic"
      min_lines: 80
    - path: "src/test/java/dev/alexandria/ingestion/chunking/LanguageDetectorTest.java"
      provides: "Unit tests for language detection"
      min_lines: 30
  key_links:
    - from: "src/main/java/dev/alexandria/ingestion/chunking/MarkdownChunker.java"
      to: "src/main/java/dev/alexandria/ingestion/chunking/DocumentChunkData.java"
      via: "returns List<DocumentChunkData>"
      pattern: "List<DocumentChunkData>"
    - from: "src/main/java/dev/alexandria/ingestion/chunking/MarkdownChunker.java"
      to: "src/main/java/dev/alexandria/ingestion/chunking/LanguageDetector.java"
      via: "calls LanguageDetector.detect() for unlabeled code blocks"
      pattern: "LanguageDetector\\.detect"
---

<objective>
Implement the Markdown chunking engine: AST-based heading splitter, code block extractor, language detector, and chunk data record -- the pure transformation layer that converts raw Markdown into richly-annotated chunks.

Purpose: This is the quality-critical core of the ingestion pipeline. Every decision about chunk boundaries, code extraction, and metadata enrichment happens here. All logic is pure (no Spring, no database, no I/O) making it ideal for TDD.
Output: MarkdownChunker, DocumentChunkData, LanguageDetector with comprehensive unit tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ingestion-pipeline/04-RESEARCH.md
@.planning/phases/04-ingestion-pipeline/04-CONTEXT.md
@gradle/libs.versions.toml
@build.gradle.kts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add commonmark-java dependencies and create DocumentChunkData record</name>
  <files>
    gradle/libs.versions.toml
    build.gradle.kts
    src/main/java/dev/alexandria/ingestion/chunking/DocumentChunkData.java
  </files>
  <action>
1. Add commonmark-java 0.27.1 to `gradle/libs.versions.toml`:
   - In `[versions]`: `commonmark = "0.27.1"`
   - In `[libraries]`: `commonmark = { module = "org.commonmark:commonmark", version.ref = "commonmark" }` and `commonmark-ext-gfm-tables = { module = "org.commonmark:commonmark-ext-gfm-tables", version.ref = "commonmark" }`

2. Add to `build.gradle.kts` dependencies block:
   - `implementation(libs.commonmark)`
   - `implementation(libs.commonmark.ext.gfm.tables)`

3. Create `DocumentChunkData.java` as a Java record in `dev.alexandria.ingestion.chunking` package:
   - Fields: `String text`, `String sourceUrl`, `String sectionPath`, `String contentType`, `String lastUpdated`, `String language`
   - `contentType` is either `"prose"` or `"code"`
   - `language` is null for prose chunks, populated for code chunks
   - No validation here -- validation happens at the MarkdownChunker level (not a DTO boundary)

4. Run `./gradlew compileJava` to confirm dependency resolution and compilation.
  </action>
  <verify>`./gradlew compileJava` succeeds with no errors. DocumentChunkData record exists with 6 fields.</verify>
  <done>commonmark-java 0.27.1 + tables extension on classpath. DocumentChunkData record compiles and is importable.</done>
</task>

<feature>
  <name>Feature: MarkdownChunker and LanguageDetector (TDD)</name>
  <files>
    src/main/java/dev/alexandria/ingestion/chunking/MarkdownChunker.java
    src/main/java/dev/alexandria/ingestion/chunking/LanguageDetector.java
    src/test/java/dev/alexandria/ingestion/chunking/MarkdownChunkerTest.java
    src/test/java/dev/alexandria/ingestion/chunking/LanguageDetectorTest.java
  </files>
  <behavior>
MarkdownChunker.chunk(String markdown, String sourceUrl, String lastUpdated) -> List&lt;DocumentChunkData&gt;

**LanguageDetector test cases:**
- `detect("public class Foo { }")` -> "java" (matches `public class ` pattern)
- `detect("def foo():\n    pass")` -> "python" (matches `def ` pattern)
- `detect("const x = 1; console.log(x)")` -> "javascript" (matches `const ` + `console.log`)
- `detect("SELECT * FROM users WHERE id = 1")` -> "sql" (matches `SELECT ` + `FROM ` + `WHERE `)
- `detect("some random text with no indicators")` -> "unknown" (no patterns match >= 2)
- `detect("func main() { fmt.Println() }")` -> "go"

**MarkdownChunker test cases:**

Case 1 -- Basic heading split:
```
# Introduction
Some intro text.
## Getting Started
Getting started text.
### Configuration
Config details here.
```
Expected: 3 prose chunks with section_paths "introduction", "introduction/getting-started", "introduction/getting-started/configuration"

Case 2 -- Code block extraction:
```
## Setup
Install the package.
```java
import com.example.Foo;
```
Then configure it.
```
Expected: 1 prose chunk ("Install the package.\nThen configure it." with content_type=prose), 1 code chunk (content_type=code, language=java)

Case 3 -- H4+ stays in parent H3:
```
### API Reference
Main API docs.
#### Methods
Method details.
#### Properties
Property details.
```
Expected: 1 chunk containing all text including H4 headings (section_path ends at H3)

Case 4 -- Heading inside code block NOT treated as split:
```
## Example
Here is a markdown example:
```markdown
## This Is Not A Real Heading
Some content.
```
```
Expected: 1 prose chunk + 1 code chunk. The `## This Is Not A Real Heading` must NOT create a split.

Case 5 -- Multiple code blocks in one section:
```
## Examples
First example:
```java
class Foo {}
```
Second example:
```python
class Foo: pass
```
```
Expected: 1 prose chunk + 2 code chunks (one java, one python). All share the same section_path.

Case 6 -- Code block without language tag (auto-detection):
```
## Config
```
public class Main { public static void main(String[] args) {} }
```
```
Expected: 1 code chunk with language detected as "java" by LanguageDetector heuristic.

Case 7 -- Section with only code blocks (no prose):
```
## Snippet
```bash
echo "hello"
```
```
Expected: 1 code chunk (language=bash), NO empty prose chunk.

Case 8 -- Empty document:
`""` -> empty list

Case 9 -- Content before first heading:
```
This is a preamble before any heading.
## First Section
Content here.
```
Expected: 2 chunks. Preamble chunk with empty section_path. First Section chunk with section_path "first-section".

Case 10 -- Metadata completeness:
Every chunk must have all 5 metadata fields populated (source_url from parameter, section_path from heading hierarchy, content_type prose or code, last_updated from parameter, language null for prose / detected for code).

Case 11 -- Table preservation:
```
## Data
| Name | Value |
|------|-------|
| foo  | bar   |
```
Expected: 1 prose chunk. Table content preserved (NOT split by pipe characters). Requires TablesExtension.
  </behavior>
  <implementation>
**LanguageDetector** (implement first, MarkdownChunker depends on it):
- Static utility class with `public static String detect(String code)` method
- Map of language -> List of keyword/pattern strings (java, python, javascript, typescript, yaml, xml, sql, bash, go, rust -- 10 languages)
- Score each language by counting how many of its patterns appear in the code
- Return highest-scoring language if score >= 2, else "unknown"
- Patterns from research: e.g., java = ["public class ", "private ", "import java.", "@Override", "System.out.", "public static void main"]
- Case-sensitive matching (keywords like `SELECT` for SQL are uppercase)

**MarkdownChunker:**
- Spring `@Component` bean (stateless, can be singleton)
- Constructor creates `Parser` with `TablesExtension.create()`
- `chunk()` method: parse markdown to AST, walk document child nodes via `getFirstChild()` / `getNext()`
- Track heading hierarchy in `String[3]` array (index 0=H1, 1=H2, 2=H3)
- When encountering `Heading` with level <= 3: flush previous section, update heading path, clear deeper levels
- When encountering `FencedCodeBlock`: collect separately from prose nodes
- When encountering any other block node: add to current prose nodes
- `emitChunks()`: build section_path from heading array using slash separator with slugification. Emit prose chunk if prose text is not blank. Emit code chunks for each FencedCodeBlock.
- Prose text extraction: Use source spans (`node.getSourceSpans()`) to extract original Markdown text from the input string, preserving formatting. The heading node itself should be included in the prose text. If source spans are unavailable or unreliable, fall back to `TextContentRenderer` for plain text.
- Section path slugification: lowercase, replace non-alphanumeric with hyphens, collapse consecutive hyphens, trim leading/trailing hyphens.
- Language detection for code blocks: use `FencedCodeBlock.getInfo()`, split on whitespace, take first token. If empty/null, call `LanguageDetector.detect()`.
- Handle content before first heading: treat as a section with empty heading path.
- Do NOT implement overlap (user decision: no overlap).
- Do NOT split at H4/H5/H6 (user decision: H4+ stays in parent H3).
  </implementation>
</feature>

</tasks>

<verification>
```bash
./gradlew test --tests "dev.alexandria.ingestion.chunking.*"
```
All unit tests pass. Tests cover: heading splitting, code extraction, language detection, metadata completeness, edge cases (empty doc, no heading, H4+, headings in code blocks).
</verification>

<success_criteria>
- MarkdownChunker splits at H1/H2/H3 boundaries only
- H4+ headings remain inside parent chunk
- FencedCodeBlocks extracted as separate code chunks with language tag
- Prose chunks contain section text minus code blocks
- Section paths use slash-separated slugified heading hierarchy
- LanguageDetector returns correct language for common languages, "unknown" for ambiguous
- All 11 test cases pass
- No Spring context required for tests (pure unit tests)
</success_criteria>

<output>
After completion, create `.planning/phases/04-ingestion-pipeline/04-01-SUMMARY.md`
</output>
