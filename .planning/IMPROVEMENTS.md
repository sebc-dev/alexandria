# Am√©liorations post-review ‚Äî phase-3/web-crawling

PR: https://github.com/sebc-dev/alexandria/pull/9
Review: 19 fichiers, 45 üü¢, 30 üü°, 0 üî¥
Progression: **8/15 compl√©t√©es**

---

## Robustesse production (priorit√© haute)

- [x] **1. Retry avec backoff sur Crawl4AiClient.crawl()**
  - Fichiers: `Crawl4AiClient.java`, `application.yml`
  - Les erreurs transitoires (timeout Chromium) √©chouent directement
  - Approche: Spring Retry ou retry manuel avec backoff exponentiel

- [x] **2. Limiter la taille des sitemaps t√©l√©charg√©s**
  - Fichier: `SitemapParser.java`
  - `body(byte[].class)` charge tout en RAM, risque OOM sur sitemaps g√©ants
  - Approche: Limiter la taille du body ou utiliser du streaming

- [x] **3. Singleton Container pattern pour les tests IT**
  - Fichiers: `Crawl4AiClientIT.java`, `CrawlServiceIT.java`
  - Deux containers Crawl4AI (~4 Go RAM) d√©marr√©s en parall√®le
  - Approche: Cr√©er un `AbstractCrawl4AiIT` ou un singleton container

## Qualit√© de code (priorit√© moyenne)

- [x] **4. @JsonNaming(SnakeCaseStrategy.class) sur les DTOs Crawl4AI**
  - Fichiers: `Crawl4AiRequest`, `Crawl4AiMarkdown`, `Crawl4AiPageResult`
  - R√©sout le snake_case de mani√®re centralis√©e au lieu de noms de champs non-Java

- [x] **5. @ConfigurationProperties record au lieu de @Value**
  - Fichier: `Crawl4AiConfig.java`
  - Validation au boot, auto-compl√©tion IDE, `/actuator/configprops`

- [x] **6. Factoriser normalizeToBase dans UrlNormalizer**
  - Fichiers: `SitemapParser.java`, `UrlNormalizer.java`
  - Duplication de logique scheme+host+port

- [x] **7. Extraire helper extractMarkdown() dans Crawl4AiClient**
  - Fichier: `Crawl4AiClient.java`
  - Ternaire imbriqu√©e difficile √† lire

- [x] **8. Factoriser setup Testcontainers Crawl4AI**
  - Fichiers: `Crawl4AiClientIT.java`, `CrawlServiceIT.java`
  - Copi√©-coll√© + image `0.8.0` dupliqu√©e √† 3 endroits (docker-compose + 2 tests)

## Compl√©tude (priorit√© basse)

- [ ] **9. Tri alphab√©tique des query params dans UrlNormalizer**
  - Fichier: `UrlNormalizer.java`
  - `?a=1&b=2` vs `?b=2&a=1` produit deux URLs distinctes

- [ ] **10. Enrichir les tests unitaires UrlNormalizer**
  - Fichier: `UrlNormalizerTest.java`
  - Manque: port d√©faut (443‚Üíomis), query params mixtes, null/blank, ports diff√©rents dans isSameSite

- [ ] **11. Collecter les pages en √©chec dans CrawlService**
  - Fichier: `CrawlService.java`
  - Retourner `CrawlSiteResult(successPages, failedUrls)` pour le monitoring

- [ ] **12. Crawl concurrent dans CrawlService**
  - Fichier: `CrawlService.java`
  - S√©quentiel actuellement, lent pour 500+ pages

## Cosm√©tique (nice to have)

- [ ] **13. Regrouper d√©pendances par domaine dans build.gradle.kts**
- [ ] **14. Port Crawl4AI optionnel dans docker-compose.yml pour debug local**
- [ ] **15. Retirer @JsonIgnoreProperties de Crawl4AiRequest** (inutile sur un objet s√©rialis√©)
