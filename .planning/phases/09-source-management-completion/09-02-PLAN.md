---
phase: 09-source-management-completion
plan: 02
type: execute
wave: 2
depends_on:
  - "09-01"
files_modified:
  - src/main/java/dev/alexandria/mcp/McpToolService.java
  - src/main/java/dev/alexandria/source/SourceRepository.java
  - src/test/java/dev/alexandria/mcp/McpToolServiceTest.java
autonomous: true
requirements:
  - SRC-02
  - SRC-03
  - SRC-04
  - SRC-05

must_haves:
  truths:
    - "list_sources shows real-time chunk count with content_type breakdown per source"
    - "list_sources and crawl_status expose last_crawled_at as ISO date"
    - "remove_source cancels active crawl, counts chunks, and returns feedback with chunk count"
    - "index_statistics MCP tool returns total chunks, total sources, storage size, embedding dimensions, last activity"
    - "updateSourceNameMetadata is called when source name changes during recrawl"
  artifacts:
    - path: "src/main/java/dev/alexandria/mcp/McpToolService.java"
      provides: "Enhanced remove_source, list_sources with real chunk count, index_statistics tool, updateSourceNameMetadata wiring"
      contains: "indexStatistics"
    - path: "src/main/java/dev/alexandria/source/SourceRepository.java"
      provides: "findMaxLastCrawledAt query"
      contains: "findMaxLastCrawledAt"
    - path: "src/test/java/dev/alexandria/mcp/McpToolServiceTest.java"
      provides: "Tests for all MCP tool enhancements"
      contains: "indexStatistics"
  key_links:
    - from: "src/main/java/dev/alexandria/mcp/McpToolService.java"
      to: "src/main/java/dev/alexandria/document/DocumentChunkRepository.java"
      via: "countBySourceId, countBySourceIdGroupedByContentType, countAllChunks, getStorageSizeBytes"
      pattern: "countBySourceId|countAllChunks|getStorageSizeBytes"
    - from: "src/main/java/dev/alexandria/mcp/McpToolService.java"
      to: "src/main/java/dev/alexandria/crawl/CrawlProgressTracker.java"
      via: "cancelCrawl in removeSource"
      pattern: "cancelCrawl"
---

<objective>
Upgrade all source management MCP tools to use correct data from Plan 01 fixes, add the new index_statistics tool, and wire updateSourceNameMetadata for recrawl.

Purpose: Closes SRC-02 (accurate list_sources), SRC-03 (cascade delete with feedback), SRC-04 (last_crawled_at exposure), and SRC-05 (index statistics). Also formally satisfies SRC-01 (add_source, already functional).

Output: All 7 MCP tools functional with accurate data, index_statistics tool providing global stats.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-source-management-completion/09-RESEARCH.md
@.planning/phases/09-source-management-completion/09-01-SUMMARY.md
@src/main/java/dev/alexandria/mcp/McpToolService.java
@src/main/java/dev/alexandria/source/SourceRepository.java
@src/main/java/dev/alexandria/document/DocumentChunkRepository.java
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhanced MCP tools + index_statistics + updateSourceNameMetadata wiring</name>
  <files>
    src/main/java/dev/alexandria/mcp/McpToolService.java
    src/main/java/dev/alexandria/source/SourceRepository.java
    src/main/java/dev/alexandria/document/DocumentChunkRepository.java
  </files>
  <action>
    **SourceRepository** -- Add query for last activity timestamp:
    ```java
    @Query("SELECT MAX(s.lastCrawledAt) FROM Source s")
    Instant findMaxLastCrawledAt();
    ```

    **DocumentChunkRepository** -- Add two global stat queries (in addition to the three from Plan 01):
    1. `countAllChunks()` -- `SELECT COUNT(*) FROM document_chunks` (returns `long`)
    2. `getStorageSizeBytes()` -- `SELECT pg_total_relation_size('document_chunks')` (returns `long`)

    **McpToolService** -- Modify these methods:

    **1. listSources()** -- Replace `source.getChunkCount()` with real-time count:
    - For each source, call `documentChunkRepository.countBySourceIdGroupedByContentType(source.getId())`
    - Format as: `"chunks: 1247 (892 prose, 355 code)"` per user decision
    - If no chunks: show `"chunks: 0"`
    - Add a private helper `formatChunkCount(UUID sourceId)` that:
      - Calls `countBySourceIdGroupedByContentType`
      - Sums total, formats breakdown string
      - Returns formatted string like `"1247 (892 prose, 355 code)"` or `"0"`
    - Keep `last_crawled_at` as ISO date (already present via `source.getLastCrawledAt().toString()`, which produces ISO-8601)
    - Updated format per source line: `"- {name} ({url}): {status} | chunks: {formatted} | last crawled: {iso_date}"`

    **2. removeSource()** -- Complete rewrite for gap closure:
    ```java
    UUID uuid = parseUuid(sourceId);
    Optional<Source> found = sourceRepository.findById(uuid);
    if (found.isEmpty()) {
        return "Error: Source %s not found.".formatted(sourceId);
    }
    Source source = found.get();

    // Cancel active crawl if running
    if (source.getStatus() == SourceStatus.CRAWLING
            || source.getStatus() == SourceStatus.UPDATING) {
        progressTracker.cancelCrawl(uuid);
        Thread.sleep(500);  // Brief wait for crawl loop to observe cancellation
    }

    // Count chunks before deletion for feedback
    long chunkCount = documentChunkRepository.countBySourceId(uuid);

    // Delete source (ON DELETE CASCADE handles chunks + ingestion_state)
    sourceRepository.deleteById(uuid);
    progressTracker.removeCrawl(uuid);

    return "Source '%s' removed (%,d chunks deleted).".formatted(source.getName(), chunkCount);
    ```
    Keep existing exception handling structure (IllegalArgumentException for bad UUID, general Exception).

    **3. crawlStatus() / formatCompletedSummary()** -- Replace `source.getChunkCount()` with real count:
    - Call `formatChunkCount(source.getId())` instead of `source.getChunkCount()`
    - `last_crawled_at` is already exposed as ISO date -- no change needed (verify it's present)

    **4. recrawlSource()** -- Wire updateSourceNameMetadata:
    After the existing version update block (lines ~262-266), add a parallel name update:
    ```java
    // Update source name metadata if name changed (currently name doesn't change,
    // but this wires the orphaned updateSourceNameMetadata method for future use)
    ```
    Since `recrawlSource` has no `name` parameter, add one:
    - Add `@ToolParam(description = "Update the display name for this source", required = false) String name` parameter
    - If `name != null && !name.equals(source.getName())`: update source.setName(name), save, call `documentChunkRepository.updateSourceNameMetadata(source.getUrl(), name)`
    - Place this alongside the existing version update block, using the same pattern

    **5. New indexStatistics() tool:**
    ```java
    @Tool(name = "index_statistics",
          description = "View global index statistics: total chunks, sources, storage size, "
                      + "embedding dimensions, and last activity timestamp.")
    public String indexStatistics() {
        try {
            long totalChunks = documentChunkRepository.countAllChunks();
            long totalSources = sourceRepository.count();
            long storageSizeBytes = documentChunkRepository.getStorageSizeBytes();
            Instant lastActivity = sourceRepository.findMaxLastCrawledAt();

            return """
                    Index Statistics:
                    - Total chunks: %,d
                    - Total sources: %d
                    - Embedding dimensions: 384 (bge-small-en-v1.5-q)
                    - Storage size: %s
                    - Last activity: %s""".formatted(
                    totalChunks, totalSources,
                    formatBytes(storageSizeBytes),
                    lastActivity != null ? lastActivity.toString() : "never");
        } catch (Exception e) {
            return "Error retrieving index statistics: " + e.getMessage();
        }
    }
    ```
    Add private `formatBytes(long bytes)` helper returning human-readable size (e.g., "245.3 MB"):
    ```java
    private static String formatBytes(long bytes) {
        if (bytes < 1024) return bytes + " B";
        double kb = bytes / 1024.0;
        if (kb < 1024) return "%.1f KB".formatted(kb);
        double mb = kb / 1024.0;
        if (mb < 1024) return "%.1f MB".formatted(mb);
        double gb = mb / 1024.0;
        return "%.1f GB".formatted(gb);
    }
    ```

    **6. Update Javadoc** on McpToolService class:
    - Update tool list from 6 to 7 tools (add `index_statistics` to the Javadoc)
    - Update `@see` references if needed

    **IMPORTANT per user decisions:**
    - No stale/fresh label -- just ISO date exposure (already the case)
    - chunk_count as real-time COUNT with content_type breakdown: "chunks: 1247 (892 prose, 355 code)"
    - remove_source: no confirmation param, feedback with count, cancel active crawl
    - index_statistics: global only, no parameters, 5 metrics
  </action>
  <verify>
    - `./quality.sh test` passes (existing tests may need constructor updates for new dependencies)
    - Grep: `grep "index_statistics" src/main/java/dev/alexandria/mcp/McpToolService.java` confirms tool exists
    - Grep: `grep "cancelCrawl" src/main/java/dev/alexandria/mcp/McpToolService.java` confirms wiring in removeSource
    - Grep: `grep "countBySourceIdGroupedByContentType" src/main/java/dev/alexandria/mcp/McpToolService.java` confirms real chunk count
  </verify>
  <done>
    - listSources shows real-time chunk count with content_type breakdown per source
    - removeSource cancels active crawl, counts chunks before deletion, returns "Source 'X' removed (N chunks deleted)."
    - crawlStatus/formatCompletedSummary uses real chunk count
    - recrawlSource accepts optional name parameter and calls updateSourceNameMetadata when name changes
    - indexStatistics tool returns total chunks, total sources, embedding dims, storage size, last activity
    - formatBytes helper produces human-readable storage sizes
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for all MCP tool enhancements</name>
  <files>
    src/test/java/dev/alexandria/mcp/McpToolServiceTest.java
  </files>
  <action>
    Update McpToolServiceTest to cover all Plan 02 changes. The test class already uses Mockito with spy pattern and suppressAsyncDispatch helper.

    **Setup changes:**
    - No new mock dependencies needed (DocumentChunkRepository already injected in Phase 8)

    **New/updated tests:**

    *listSources:*
    - `listSourcesShowsRealChunkCountWithContentTypeBreakdown` -- Mock `countBySourceIdGroupedByContentType` to return `[["prose", 892], ["code", 355]]`. Assert output contains `"chunks: 1247 (892 prose, 355 code)"`.
    - `listSourcesShowsZeroChunksForNewSource` -- Mock `countBySourceIdGroupedByContentType` to return empty list. Assert output contains `"chunks: 0"`.
    - `listSourcesShowsLastCrawledAtAsIsoDate` -- Create source with `lastCrawledAt = Instant.parse("2026-02-20T14:30:00Z")`. Assert output contains `"2026-02-20T14:30:00Z"`.

    *removeSource:*
    - `removeSourceCancelsActiveCrawlAndReturnsChunkCount` -- Create source with CRAWLING status. Mock `countBySourceId` to return 1247. Call removeSource. Verify: `progressTracker.cancelCrawl(uuid)` called, `sourceRepository.deleteById(uuid)` called, output contains `"1,247 chunks deleted"`.
    - `removeSourceDeletesIdleSourceWithFeedback` -- Create source with INDEXED status. Mock countBySourceId=42. Verify: cancelCrawl NOT called, output contains `"42 chunks deleted"`.
    - `removeSourceReturnsErrorForNotFound` -- Mock findById empty. Assert output starts with `"Error:"`.

    *recrawlSource:*
    - `recrawlSourceUpdatesNameWhenChanged` -- Create source with name "Old Name". Call with name="New Name". Verify: `source.getName()` not equal assertion not needed (mock), verify `documentChunkRepository.updateSourceNameMetadata(url, "New Name")` called, verify `sourceRepository.save` called.
    - `recrawlSourceSkipsNameUpdateWhenNull` -- Call with name=null. Verify updateSourceNameMetadata NOT called.

    *indexStatistics:*
    - `indexStatisticsReturnsFormattedGlobalStats` -- Mock: countAllChunks=4521, sourceRepository.count()=3, getStorageSizeBytes=257_163_264L (~245.3 MB), findMaxLastCrawledAt=Instant. Assert output contains "Total chunks: 4,521", "Total sources: 3", "384", "245.3 MB", ISO timestamp.
    - `indexStatisticsHandlesEmptyIndex` -- Mock: all zeros, findMaxLastCrawledAt=null. Assert contains "0", "never".
    - `indexStatisticsHandlesException` -- Mock countAllChunks to throw. Assert output starts with "Error".

    *crawlStatus:*
    - Update `crawlStatusShowsCompletedSummary` (if it exists) to verify real chunk count from formatChunkCount instead of source.getChunkCount(). Mock `countBySourceIdGroupedByContentType` appropriately.

    Follow existing test naming convention (camelCase), AAA structure, one concept per test. Use SourceBuilder for Source fixtures.
  </action>
  <verify>
    - `./quality.sh test` -- all unit tests pass including new ones
    - `./quality.sh spotbugs` -- no new findings
    - `./quality.sh arch` -- architecture tests pass (no package cycles)
    - Count: at least 10 new test methods added
  </verify>
  <done>
    - All MCP tool enhancements covered by unit tests
    - listSources tests verify real chunk count with breakdown and ISO date
    - removeSource tests verify cancellation, chunk count feedback, error handling
    - recrawlSource tests verify name update and source name metadata wiring
    - indexStatistics tests verify formatted output, empty state, error handling
    - All quality gates pass with no regressions
  </done>
</task>

</tasks>

<verification>
- `./quality.sh all` -- all quality gates pass
- 7 MCP tools registered (search_docs, list_sources, add_source, remove_source, crawl_status, recrawl_source, index_statistics)
- list_sources output shows real chunk count with content_type breakdown
- remove_source returns "Source 'X' removed (N chunks deleted)."
- index_statistics returns all 5 metrics
- last_crawled_at appears in both list_sources and crawl_status as ISO date
</verification>

<success_criteria>
- SRC-01: add_source functional (already working from Phase 7, formally verified)
- SRC-02: list_sources shows accurate chunk_count with content_type breakdown + last_crawled_at
- SRC-03: remove_source cancels crawl, deletes source with CASCADE, returns chunk count feedback
- SRC-04: last_crawled_at as ISO date in list_sources and crawl_status
- SRC-05: index_statistics tool returns total chunks, sources, storage, dimensions, last activity
- updateSourceNameMetadata wired in recrawlSource when name parameter provided
</success_criteria>

<output>
After completion, create `.planning/phases/09-source-management-completion/09-02-SUMMARY.md`
</output>
